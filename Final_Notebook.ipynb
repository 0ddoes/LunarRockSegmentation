{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"l5i3N-weKP6-","papermill":{"duration":0.022866,"end_time":"2021-02-18T10:06:03.865074","exception":false,"start_time":"2021-02-18T10:06:03.842208","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\n\nfrom PIL import Image\nimport cv2\nimport albumentations as A\n\nimport time\nimport os\nfrom tqdm.notebook import tqdm\n\n!pip install -q segmentation-models-pytorch\n!pip install -q torchsummary\n\nfrom torchsummary import summary\nimport segmentation_models_pytorch as smp\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"kFSYoYRqJSfB","papermill":{"duration":23.025453,"end_time":"2021-02-18T10:06:26.911588","exception":false,"start_time":"2021-02-18T10:06:03.886135","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:07.408436Z","iopub.execute_input":"2022-03-01T15:18:07.409524Z","iopub.status.idle":"2022-03-01T15:18:30.523123Z","shell.execute_reply.started":"2022-03-01T15:18:07.409306Z","shell.execute_reply":"2022-03-01T15:18:30.522208Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"id":"1_HWVOdhJSfP","papermill":{"duration":0.026783,"end_time":"2021-02-18T10:06:26.966143","exception":false,"start_time":"2021-02-18T10:06:26.93936","status":"completed"},"tags":[]}},{"cell_type":"code","source":"IMAGE_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/render/'\nMASK_PATH = '../input/artificial-lunar-rocky-landscape-dataset/images/clean/'","metadata":{"papermill":{"duration":0.033799,"end_time":"2021-02-18T10:06:27.027862","exception":false,"start_time":"2021-02-18T10:06:26.994063","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:30.525118Z","iopub.execute_input":"2022-03-01T15:18:30.525433Z","iopub.status.idle":"2022-03-01T15:18:30.530436Z","shell.execute_reply.started":"2022-03-01T15:18:30.525404Z","shell.execute_reply":"2022-03-01T15:18:30.529387Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"n_classes = 4\n\ndef create_df(PATH):\n    name = []\n    for dirname, _, filenames in os.walk(PATH):\n        for filename in sorted(filenames):\n            name.append(filename.split('.')[0])\n    \n    return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n\nimagedf = create_df(IMAGE_PATH)\nmaskdf  = create_df(MASK_PATH)\n\nprint('Total Images: ', len(imagedf))\nprint('Total masks: ', len(maskdf))","metadata":{"id":"gmPIy2ZFJSfQ","outputId":"895760d0-0896-49e9-b90b-3a06dc227886","papermill":{"duration":0.157328,"end_time":"2021-02-18T10:06:27.211938","exception":false,"start_time":"2021-02-18T10:06:27.05461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:30.531915Z","iopub.execute_input":"2022-03-01T15:18:30.532680Z","iopub.status.idle":"2022-03-01T15:18:43.331477Z","shell.execute_reply.started":"2022-03-01T15:18:30.532640Z","shell.execute_reply":"2022-03-01T15:18:43.330722Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"maskdf.tail()","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:43.332664Z","iopub.execute_input":"2022-03-01T15:18:43.333000Z","iopub.status.idle":"2022-03-01T15:18:43.353497Z","shell.execute_reply.started":"2022-03-01T15:18:43.332972Z","shell.execute_reply":"2022-03-01T15:18:43.352688Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#split data\nX_trainval, X_test = train_test_split(imagedf, test_size=0.1, random_state=19)\nX_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n\ny_trainval, y_test = train_test_split(maskdf, test_size=0.1, random_state=19)\ny_train, y_val = train_test_split(y_trainval, test_size=0.15, random_state=19)\n\nprint('Train Size   : ', len(X_train))\nprint('Val Size     : ', len(X_val))\nprint('Test Size    : ', len(X_test))\nprint('Train Size   : ', len(y_train))\nprint('Val Size     : ', len(y_val))\nprint('Test Size    : ', len(y_test))","metadata":{"papermill":{"duration":0.045372,"end_time":"2021-02-18T10:06:27.28512","exception":false,"start_time":"2021-02-18T10:06:27.239748","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:43.357507Z","iopub.execute_input":"2022-03-01T15:18:43.357787Z","iopub.status.idle":"2022-03-01T15:18:43.383609Z","shell.execute_reply.started":"2022-03-01T15:18:43.357761Z","shell.execute_reply":"2022-03-01T15:18:43.382912Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train_lis = list(X_train['id'])\ny_train_lis = list(y_train['id'])\nX_val_lis = list(X_val['id'])\ny_val_lis = list(y_val['id'])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:43.386680Z","iopub.execute_input":"2022-03-01T15:18:43.386964Z","iopub.status.idle":"2022-03-01T15:18:43.397360Z","shell.execute_reply.started":"2022-03-01T15:18:43.386924Z","shell.execute_reply":"2022-03-01T15:18:43.396249Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_test_lis = list(X_test['id'])\ny_test_lis = list(y_test['id'])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:43.398927Z","iopub.execute_input":"2022-03-01T15:18:43.399545Z","iopub.status.idle":"2022-03-01T15:18:43.407821Z","shell.execute_reply.started":"2022-03-01T15:18:43.399505Z","shell.execute_reply":"2022-03-01T15:18:43.406718Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"id = 14\nimg = cv2.imread(IMAGE_PATH + imagedf['id'][id] + '.png')\nmask = cv2.imread(MASK_PATH + maskdf['id'][id] + '.png', cv2.IMREAD_GRAYSCALE)\nmask = mask//29\nmask[mask == 5] = 3\nprint('Image Size', np.asarray(img).shape)\nprint('Mask Size', np.asarray(mask).shape)\n\nplt.imshow(img)\n# plt.title('Picture with Mask Applied')\nplt.show()","metadata":{"id":"-uXF6vetJSff","outputId":"3dbf6719-75ed-46f7-805c-7892b7b3a6d1","papermill":{"duration":4.280771,"end_time":"2021-02-18T10:06:31.595115","exception":false,"start_time":"2021-02-18T10:06:27.314344","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:43.409333Z","iopub.execute_input":"2022-03-01T15:18:43.410071Z","iopub.status.idle":"2022-03-01T15:18:43.674282Z","shell.execute_reply.started":"2022-03-01T15:18:43.409988Z","shell.execute_reply":"2022-03-01T15:18:43.673327Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"i, v = np.unique(mask, return_counts = True)\nfor a,b in zip(i,v):\n    print(a,\" \", b)\nplt.imshow(mask)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:43.675398Z","iopub.execute_input":"2022-03-01T15:18:43.675772Z","iopub.status.idle":"2022-03-01T15:18:43.855404Z","shell.execute_reply.started":"2022-03-01T15:18:43.675734Z","shell.execute_reply":"2022-03-01T15:18:43.854520Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"mask = cv2.imread(MASK_PATH + maskdf['id'][id] + '.png')\nplt.imshow(mask)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:43.856717Z","iopub.execute_input":"2022-03-01T15:18:43.857229Z","iopub.status.idle":"2022-03-01T15:18:44.033611Z","shell.execute_reply.started":"2022-03-01T15:18:43.857189Z","shell.execute_reply":"2022-03-01T15:18:44.032570Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"id":"dkjFEoe7JSfo","papermill":{"duration":0.030107,"end_time":"2021-02-18T10:06:31.656378","exception":false,"start_time":"2021-02-18T10:06:31.626271","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class LunarDataset(Dataset):\n    \n    def __init__(self, img_path, mask_path, X, y, mean, std, transform=None, patch=False):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.y = y\n        self.transform = transform\n        self.patches = patch\n        self.mean = mean\n        self.std = std\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.mask_path + self.y[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n        mask = mask//29\n        mask[mask==5] = 3\n        \n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask)\n            img = Image.fromarray(aug['image'])\n            mask = aug['mask']\n        \n        if self.transform is None:\n            img = Image.fromarray(img)\n        \n        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n        img = t(img)\n        mask = torch.from_numpy(mask).long()\n        \n        if self.patches:\n            img, mask = self.tiles(img, mask)\n            \n        return img, mask\n    \n    def tiles(self, img, mask):\n\n        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768) \n        img_patches  = img_patches.contiguous().view(3,-1, 512, 768) \n        img_patches = img_patches.permute(1,0,2,3)\n        \n        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n        \n        return img_patches, mask_patches","metadata":{"id":"yne-vteuJSfp","papermill":{"duration":0.045449,"end_time":"2021-02-18T10:06:31.732603","exception":false,"start_time":"2021-02-18T10:06:31.687154","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:44.034906Z","iopub.execute_input":"2022-03-01T15:18:44.035303Z","iopub.status.idle":"2022-03-01T15:18:44.047531Z","shell.execute_reply.started":"2022-03-01T15:18:44.035274Z","shell.execute_reply":"2022-03-01T15:18:44.046505Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"mean=[0.485, 0.456, 0.406]\nstd=[0.229, 0.224, 0.225]\n\nt_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), \n#                      A.GridDistortion(p=0.2),\n#                      A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n#                      A.GaussNoise()\n                    ])\n# \nt_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n                   A.GridDistortion(p=0.2)])\n\n#datasets\ntrain_set = LunarDataset(IMAGE_PATH, MASK_PATH, X_train_lis, y_train_lis, mean, std,t_train, patch=False)\nval_set = LunarDataset(IMAGE_PATH, MASK_PATH, X_val_lis, y_val_lis, mean, std,t_val, patch=False)\n\n#dataloader\nbatch_size= 3\n\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)      ","metadata":{"id":"CCL93_giJSft","papermill":{"duration":0.041706,"end_time":"2021-02-18T10:06:31.80439","exception":false,"start_time":"2021-02-18T10:06:31.762684","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:44.048879Z","iopub.execute_input":"2022-03-01T15:18:44.049430Z","iopub.status.idle":"2022-03-01T15:18:44.062495Z","shell.execute_reply.started":"2022-03-01T15:18:44.049390Z","shell.execute_reply":"2022-03-01T15:18:44.061691Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"img, mask = next(iter(train_loader))\nplt.imshow(img[2].permute(1,2,0))","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:44.064208Z","iopub.execute_input":"2022-03-01T15:18:44.064596Z","iopub.status.idle":"2022-03-01T15:18:44.588912Z","shell.execute_reply.started":"2022-03-01T15:18:44.064557Z","shell.execute_reply":"2022-03-01T15:18:44.588076Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"plt.imshow(mask[2])\n# print(mask[2][150])","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:44.590285Z","iopub.execute_input":"2022-03-01T15:18:44.590809Z","iopub.status.idle":"2022-03-01T15:18:44.784726Z","shell.execute_reply.started":"2022-03-01T15:18:44.590774Z","shell.execute_reply":"2022-03-01T15:18:44.783891Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"jJ-ZypiFJSgJ","papermill":{"duration":0.029797,"end_time":"2021-02-18T10:06:31.864199","exception":false,"start_time":"2021-02-18T10:06:31.834402","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=4, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])","metadata":{"id":"ZXb8nBmpJSgK","outputId":"167e4afc-a54d-455b-ed0e-328558cfe23f","papermill":{"duration":0.637787,"end_time":"2021-02-18T10:06:32.532384","exception":false,"start_time":"2021-02-18T10:06:31.894597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:44.786173Z","iopub.execute_input":"2022-03-01T15:18:44.786527Z","iopub.status.idle":"2022-03-01T15:18:45.957455Z","shell.execute_reply.started":"2022-03-01T15:18:44.786490Z","shell.execute_reply":"2022-03-01T15:18:45.956358Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/waleedka/hiddenlayer.git\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:45.962348Z","iopub.execute_input":"2022-03-01T15:18:45.964642Z","iopub.status.idle":"2022-03-01T15:18:54.764820Z","shell.execute_reply.started":"2022-03-01T15:18:45.964602Z","shell.execute_reply":"2022-03-01T15:18:54.763945Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# import hiddenlayer as hl\n\n# transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n# inp = torch.zeros([1, 3, 704, 1056])\n# inp = inp.to(device)\n# graph = hl.build_graph(model, inp, transforms = transforms)\n# graph.theme = hl.graph.THEMES['blue'].copy()\n# # graph.save('rnn_hiddenlayer', format='png')\n# graph","metadata":{"id":"32nY_jBWJSgN","papermill":{"duration":0.043393,"end_time":"2021-02-18T10:06:32.607492","exception":false,"start_time":"2021-02-18T10:06:32.564099","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:19:41.421704Z","iopub.execute_input":"2022-03-01T15:19:41.422090Z","iopub.status.idle":"2022-03-01T15:19:41.426360Z","shell.execute_reply.started":"2022-03-01T15:19:41.422044Z","shell.execute_reply":"2022-03-01T15:19:41.425038Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# input_names = ['Input Image']\n# output_names = ['Output Mask']\n# torch.onnx.export(model, inp, 'rnn.onnx', input_names=input_names, output_names=output_names)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:20:05.670508Z","iopub.execute_input":"2022-03-01T15:20:05.670848Z","iopub.status.idle":"2022-03-01T15:20:05.675206Z","shell.execute_reply.started":"2022-03-01T15:20:05.670816Z","shell.execute_reply":"2022-03-01T15:20:05.674205Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# !pip install torchviz","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:59.056879Z","iopub.status.idle":"2022-03-01T15:18:59.057576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchviz import make_dot\n# inp = torch.zeros([1, 3, 704, 1056])\n# inp = inp.to(device)\n# yhat = model(inp)\n# make_dot(yhat, params=dict(list(model.named_parameters())), show_attrs=True, show_saved=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T15:18:59.058669Z","iopub.status.idle":"2022-03-01T15:18:59.059333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"ncudHa0UJSgQ","papermill":{"duration":0.031715,"end_time":"2021-02-18T10:06:32.670851","exception":false,"start_time":"2021-02-18T10:06:32.639136","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def pixel_accuracy(output, mask):\n    with torch.no_grad():\n        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n        correct = torch.eq(output, mask).int()\n        accuracy = float(correct.sum()) / float(correct.numel())\n    return accuracy","metadata":{"papermill":{"duration":0.039711,"end_time":"2021-02-18T10:06:32.742919","exception":false,"start_time":"2021-02-18T10:06:32.703208","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:20:23.094230Z","iopub.execute_input":"2022-03-01T15:20:23.094553Z","iopub.status.idle":"2022-03-01T15:20:23.099413Z","shell.execute_reply.started":"2022-03-01T15:20:23.094523Z","shell.execute_reply":"2022-03-01T15:20:23.098487Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def mIoU(pred_mask, mask, smooth=1e-10, n_classes=4):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n\n        iou_per_class = []\n        for clas in range(0, n_classes): #loop per pixel class\n            true_class = pred_mask == clas\n            true_label = mask == clas\n\n            if true_label.long().sum().item() == 0: #no exist label in this loop\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n                union = torch.logical_or(true_class, true_label).sum().float().item()\n\n                iou = (intersect + smooth) / (union +smooth)\n                iou_per_class.append(iou)\n        return np.nanmean(iou_per_class)","metadata":{"id":"5cqfcLtOJSgS","papermill":{"duration":0.048322,"end_time":"2021-02-18T10:06:32.826838","exception":false,"start_time":"2021-02-18T10:06:32.778516","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:20:25.554870Z","iopub.execute_input":"2022-03-01T15:20:25.555257Z","iopub.status.idle":"2022-03-01T15:20:25.575498Z","shell.execute_reply.started":"2022-03-01T15:20:25.555228Z","shell.execute_reply":"2022-03-01T15:20:25.571566Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n#     torch.cuda.empty_cache()\n    train_losses = []\n    test_losses = []\n    val_iou = []; val_acc = []\n    train_iou = []; train_acc = []\n    lrs = []\n    min_loss = np.inf\n    decrease = 1 ; not_improve=0\n\n    model.to(device)\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        iou_score = 0\n        accuracy = 0\n        #training loop\n        model.train()\n        for i, data in enumerate(tqdm(train_loader)):\n            #training phase\n            image_tiles, mask_tiles = data\n            if patch:\n                bs, n_tiles, c, h, w = image_tiles.size()\n\n                image_tiles = image_tiles.view(-1,c, h, w)\n                mask_tiles = mask_tiles.view(-1, h, w)\n            \n            image = image_tiles.to(device); mask = mask_tiles.to(device);\n            #forward\n            output = model(image)\n            loss = criterion(output, mask)\n            #evaluation metrics\n            iou_score += mIoU(output, mask)\n            accuracy += pixel_accuracy(output, mask)\n            #backward\n            loss.backward()\n            optimizer.step() #update weight          \n            optimizer.zero_grad() #reset gradient\n            \n            #step the learning rate\n            lrs.append(get_lr(optimizer))\n            scheduler.step() \n            \n            running_loss += loss.item()\n            \n        else:\n            model.eval()\n            test_loss = 0\n            test_accuracy = 0\n            val_iou_score = 0\n            #validation loop\n            with torch.no_grad():\n                for i, data in enumerate(tqdm(val_loader)):\n                    #reshape to 9 patches from single image, delete batch size\n                    image_tiles, mask_tiles = data\n\n                    if patch:\n                        bs, n_tiles, c, h, w = image_tiles.size()\n\n                        image_tiles = image_tiles.view(-1,c, h, w)\n                        mask_tiles = mask_tiles.view(-1, h, w)\n                    \n                    image = image_tiles.to(device); mask = mask_tiles.to(device);\n                    output = model(image)\n                    #evaluation metrics\n                    val_iou_score +=  mIoU(output, mask)\n                    test_accuracy += pixel_accuracy(output, mask)\n                    #loss\n                    loss = criterion(output, mask)                                  \n                    test_loss += loss.item()\n            \n            #calculate mean for each batch\n            train_losses.append(running_loss/len(train_loader))\n            test_losses.append(test_loss/len(val_loader))\n\n\n            if min_loss > (test_loss/len(val_loader)):\n                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss/len(val_loader))))\n                min_loss = (test_loss/len(val_loader))\n                decrease += 1\n                if decrease % 5 == 0:\n                    print('saving model...')\n                    torch.save(model, 'Unet2-Mobilenet_v2_mIoU-{:.3f}.pt'.format(val_iou_score/len(val_loader)))\n                    \n\n            if (test_loss/len(val_loader)) > min_loss:\n                not_improve += 1\n                min_loss = (test_loss/len(val_loader))\n                print(f'Loss Not Decrease for {not_improve} time')\n                if not_improve == 7:\n                    print('Loss not decrease for 7 times, Stop Training')\n                    break\n            \n            #iou\n            val_iou.append(val_iou_score/len(val_loader))\n            train_iou.append(iou_score/len(train_loader))\n            train_acc.append(accuracy/len(train_loader))\n            val_acc.append(test_accuracy/ len(val_loader))\n            print(\"Epoch:{}/{}..\".format(e+1, epochs),\n                  \"Train Loss: {:.3f}..\".format(running_loss/len(train_loader)),\n                  \"Val Loss: {:.3f}..\".format(test_loss/len(val_loader)),\n                  \"Train mIoU:{:.3f}..\".format(iou_score/len(train_loader)),\n                  \"Val mIoU: {:.3f}..\".format(val_iou_score/len(val_loader)),\n                  \"Train Acc:{:.3f}..\".format(accuracy/len(train_loader)),\n                  \"Val Acc:{:.3f}..\".format(test_accuracy/len(val_loader)),\n                  \"Time: {:.2f}m\".format((time.time()-since)/60))\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses,\n               'train_miou' :train_iou, 'val_miou':val_iou,\n               'train_acc' :train_acc, 'val_acc':val_acc,\n               'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n    return history","metadata":{"id":"8i9UIFUJJSgZ","papermill":{"duration":0.060048,"end_time":"2021-02-18T10:06:32.922403","exception":false,"start_time":"2021-02-18T10:06:32.862355","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:20:26.734902Z","iopub.execute_input":"2022-03-01T15:20:26.735247Z","iopub.status.idle":"2022-03-01T15:20:26.887718Z","shell.execute_reply.started":"2022-03-01T15:20:26.735217Z","shell.execute_reply":"2022-03-01T15:20:26.886655Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"max_lr = 1e-3\nepoch = 15\nweight_decay = 1e-4\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,\n                                            steps_per_epoch=len(train_loader))\n\nhistory = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)\n\n# each epoch will take almost 16-20 mins\n# mean val IOU will be 0.72 in first epoch","metadata":{"id":"vo-VQwfJJSgg","outputId":"6f9ba55a-1dc1-49e2-f4ef-6fac29b235e8","papermill":{"duration":3881.864248,"end_time":"2021-02-18T11:11:14.819081","exception":false,"start_time":"2021-02-18T10:06:32.954833","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T16:35:52.555484Z","iopub.execute_input":"2022-03-01T16:35:52.555800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'Unet2-Mobilenet.pt')","metadata":{"id":"km58PT8qvJ4g","papermill":{"duration":0.15037,"end_time":"2021-02-18T11:11:15.01764","exception":false,"start_time":"2021-02-18T11:11:14.86727","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.068219Z","iopub.status.idle":"2022-03-01T15:18:59.068872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history):\n    plt.plot(history['val_loss'], label='val', marker='o')\n    plt.plot( history['train_loss'], label='train', marker='o')\n    plt.title('Loss per epoch'); plt.ylabel('loss');\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n    \ndef plot_score(history):\n    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n    \ndef plot_acc(history):\n    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()","metadata":{"id":"ojw74huJJSgn","papermill":{"duration":0.094126,"end_time":"2021-02-18T11:11:15.563574","exception":false,"start_time":"2021-02-18T11:11:15.469448","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.070101Z","iopub.status.idle":"2022-03-01T15:18:59.070844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(history)\nplot_score(history)\nplot_acc(history)","metadata":{"id":"KT-pRvoJJSgq","outputId":"76a82c62-46ca-44db-9129-8d20ec586471","papermill":{"duration":0.71827,"end_time":"2021-02-18T11:11:16.361999","exception":false,"start_time":"2021-02-18T11:11:15.643729","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.071923Z","iopub.status.idle":"2022-03-01T15:18:59.072562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{"id":"6BdSV7zxJSgu","papermill":{"duration":0.049339,"end_time":"2021-02-18T11:11:16.461916","exception":false,"start_time":"2021-02-18T11:11:16.412577","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class LunarTestDataset(Dataset):\n    \n    def __init__(self, img_path, mask_path, X,y, transform=None):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.y = y\n        self.transform = transform\n      \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_path + self.X[idx] + '.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.mask_path + self.y[idx] + '.png', cv2.IMREAD_GRAYSCALE)\n        mask = mask//29\n        mask[mask==5] = 3\n        \n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask)\n            img = Image.fromarray(aug['image'])\n            mask = aug['mask']\n        \n        if self.transform is None:\n            img = Image.fromarray(img)\n        \n        mask = torch.from_numpy(mask).long()\n        \n        return img, mask\n\n\nt_test = A.Resize(480, 720, interpolation=cv2.INTER_NEAREST)\ntest_set = LunarTestDataset(IMAGE_PATH, MASK_PATH, X_test_lis, y_test_lis, transform=t_test)","metadata":{"id":"s9A82ZcL14-M","papermill":{"duration":0.06197,"end_time":"2021-02-18T11:11:16.573439","exception":false,"start_time":"2021-02-18T11:11:16.511469","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.073738Z","iopub.status.idle":"2022-03-01T15:18:59.074488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Result","metadata":{"id":"j0c6UnUz4gb6","papermill":{"duration":0.050775,"end_time":"2021-02-18T11:11:16.67452","exception":false,"start_time":"2021-02-18T11:11:16.623745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n    model.eval()\n    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n    image = t(image)\n    model.to(device); image=image.to(device)\n    mask = mask.to(device)\n    with torch.no_grad():\n        \n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        \n        output = model(image)\n        score = mIoU(output, mask)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n    return masked, score","metadata":{"papermill":{"duration":0.060719,"end_time":"2021-02-18T11:11:16.785872","exception":false,"start_time":"2021-02-18T11:11:16.725153","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.075860Z","iopub.status.idle":"2022-03-01T15:18:59.076645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n    model.eval()\n    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n    image = t(image)\n    model.to(device); image=image.to(device)\n    mask = mask.to(device)\n    with torch.no_grad():\n        \n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        \n        output = model(image)\n        acc = pixel_accuracy(output, mask)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n    return masked, acc","metadata":{"id":"ggsxFaduVz2O","papermill":{"duration":0.059442,"end_time":"2021-02-18T11:11:16.89527","exception":false,"start_time":"2021-02-18T11:11:16.835828","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.077891Z","iopub.status.idle":"2022-03-01T15:18:59.078684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, mask = test_set[3]\npred_mask, score = predict_image_mask_miou(model, image, mask)","metadata":{"id":"ZPPKBax53Kj7","papermill":{"duration":0.725244,"end_time":"2021-02-18T11:11:17.669662","exception":false,"start_time":"2021-02-18T11:11:16.944418","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.079815Z","iopub.status.idle":"2022-03-01T15:18:59.080492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def miou_score(model, test_set):\n    score_iou = []\n    for i in tqdm(range(len(test_set))):\n        img, mask = test_set[i]\n        pred_mask, score = predict_image_mask_miou(model, img, mask)\n        score_iou.append(score)\n    return score_iou","metadata":{"id":"-UY_OKGW-Zo5","papermill":{"duration":0.057861,"end_time":"2021-02-18T11:11:17.777536","exception":false,"start_time":"2021-02-18T11:11:17.719675","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.081672Z","iopub.status.idle":"2022-03-01T15:18:59.082404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mob_miou = miou_score(model, test_set)","metadata":{"id":"DCa1A9y8zTbg","outputId":"68e99a8d-5500-482d-ed1d-1fa78e7bd02d","papermill":{"duration":26.64397,"end_time":"2021-02-18T11:11:44.471497","exception":false,"start_time":"2021-02-18T11:11:17.827527","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.083596Z","iopub.status.idle":"2022-03-01T15:18:59.084264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pixel_acc(model, test_set):\n    accuracy = []\n    for i in tqdm(range(len(test_set))):\n        img, mask = test_set[i]\n        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n        accuracy.append(acc)\n    return accuracy","metadata":{"id":"LuexylyzXCmc","papermill":{"duration":0.058884,"end_time":"2021-02-18T11:11:44.581542","exception":false,"start_time":"2021-02-18T11:11:44.522658","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.085385Z","iopub.status.idle":"2022-03-01T15:18:59.086100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mob_acc = pixel_acc(model, test_set)","metadata":{"id":"wIEZR3w4XTFL","outputId":"fb0ed4ba-1371-4a5f-fdea-17f64135f95a","papermill":{"duration":25.407116,"end_time":"2021-02-18T11:12:10.040411","exception":false,"start_time":"2021-02-18T11:11:44.633295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.087244Z","iopub.status.idle":"2022-03-01T15:18:59.087885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\nax1.imshow(image)\nax1.set_title('Picture');\n\nax2.imshow(mask)\nax2.set_title('Ground truth')\nax2.set_axis_off()\n\nax3.imshow(pred_mask)\nax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score))\nax3.set_axis_off()","metadata":{"id":"FV6xO9SLtSum","outputId":"2bcbb0ff-987f-4596-b595-7f6614638d1f","papermill":{"duration":0.624904,"end_time":"2021-02-18T11:12:10.715853","exception":false,"start_time":"2021-02-18T11:12:10.090949","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.089176Z","iopub.status.idle":"2022-03-01T15:18:59.089823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image2, mask2 = test_set[4]\npred_mask2, score2 = predict_image_mask_miou(model, image2, mask2)\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\nax1.imshow(image2)\nax1.set_title('Picture');\n\nax2.imshow(mask2)\nax2.set_title('Ground truth')\nax2.set_axis_off()\n\nax3.imshow(pred_mask2)\nax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score2))\nax3.set_axis_off()","metadata":{"papermill":{"duration":1.113059,"end_time":"2021-02-18T11:12:11.886384","exception":false,"start_time":"2021-02-18T11:12:10.773325","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.090941Z","iopub.status.idle":"2022-03-01T15:18:59.091626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image3, mask3 = test_set[6]\npred_mask3, score3 = predict_image_mask_miou(model, image3, mask3)\n\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20,10))\nax1.imshow(image3)\nax1.set_title('Picture');\n\nax2.imshow(mask3)\nax2.set_title('Ground truth')\nax2.set_axis_off()\n\nax3.imshow(pred_mask3)\nax3.set_title('UNet-MobileNet | mIoU {:.3f}'.format(score3))\nax3.set_axis_off()","metadata":{"papermill":{"duration":1.110346,"end_time":"2021-02-18T11:12:13.062543","exception":false,"start_time":"2021-02-18T11:12:11.952197","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.092691Z","iopub.status.idle":"2022-03-01T15:18:59.093322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Set mIoU', np.mean(mob_miou))","metadata":{"id":"xxTIX8P-JSh9","outputId":"1c267692-9175-4d6d-b90f-02a8c5c21b1c","papermill":{"duration":0.079123,"end_time":"2021-02-18T11:12:13.21186","exception":false,"start_time":"2021-02-18T11:12:13.132737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.094407Z","iopub.status.idle":"2022-03-01T15:18:59.095049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Test Set Pixel Accuracy', np.mean(mob_acc))","metadata":{"id":"bcKnghXTXbAJ","outputId":"9de5a72b-6154-4373-a51d-6e17ecdf9994","papermill":{"duration":0.080048,"end_time":"2021-02-18T11:12:13.361311","exception":false,"start_time":"2021-02-18T11:12:13.281263","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-01T15:18:59.096423Z","iopub.status.idle":"2022-03-01T15:18:59.097099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}